# TDD Best Practices - Dashboard Educativo
## Mejores PrÃ¡cticas para Test-Driven Development

**Fecha:** 2025-10-02  
**Basado en:** Fuentes oficiales y documentaciÃ³n confiable  
**Proyecto:** Dashboard Educativo Full-Stack

---

## ğŸ“š Fuentes Oficiales Consultadas

### Fuentes Fundamentales
1. **Mozilla Developer Network (MDN)** - Testing frameworks y mejores prÃ¡cticas
2. **pytest Documentation** - Convenciones y estructura de tests Python
3. **Vitest Documentation** - Testing para React y TypeScript
4. **React Testing Library** - Principios de testing centrados en el usuario
5. **FastAPI Documentation** - Testing de APIs con pytest
6. **Kent Beck** - Creador de TDD, metodologÃ­a original

### Fuentes Especializadas en LLM + Testing
7. **SchÃ¤fer et al.** - [An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation](https://arxiv.org/abs/2302.06527) - Baseline de cobertura LLM: ~70.2% lÃ­neas, ~52.8% ramas
8. **Pizzorno & Berger** - [CoverUp: Coverage-Guided LLM-Based Test Generation](https://arxiv.org/abs/2403.16218) - Mejoras con feedback iterativo: ~80% mÃ³dulos, ~90% overall
9. **Ryan et al.** - [SymPrompt: Code-Aware Prompting, Coverage-Guided Test Generation](https://dl.acm.org/doi/10.1145/3643769) - Prompting code-aware incrementa cobertura significativamente
10. **Alshahwan et al.** - [Automated Unit Test Improvement using LLMs at Meta](https://arxiv.org/abs/2402.09171) - Despliegue industrial en Instagram/Facebook
11. **Alshahwan et al.** - [Observation-based unit test generation at Meta](https://arxiv.org/abs/2402.06111) - 518 tests en producciÃ³n, 9.6M ejecuciones CI
12. **Google Testing Blog** - [Code Coverage Best Practices](https://testing.googleblog.com/2020/08/code-coverage-best-practices.html) - GuÃ­as de cobertura: 60% aceptable, 75% commendable, 90% exemplary
13. **Google Testing Blog** - [Code coverage goal: 80% and no less!](https://testing.googleblog.com/2010/07/code-coverage-goal-80-and-no-less.html) - Regla simple para contextos especÃ­ficos

---

## ğŸ¯ Principios Fundamentales de TDD

### Ciclo Red-Green-Refactor

```
1. ğŸ”´ RED: Escribir un test que falle
   â†“
2. ğŸŸ¢ GREEN: Escribir el cÃ³digo mÃ­nimo para que pase
   â†“
3. ğŸ”µ REFACTOR: Mejorar el cÃ³digo manteniendo tests pasando
   â†“
4. Repetir
```

### Reglas de Oro

1. **Nunca escribas cÃ³digo de producciÃ³n sin un test fallando**
2. **Escribe solo el cÃ³digo necesario para pasar el test**
3. **Refactoriza solo cuando los tests estÃ©n en verde**
4. **Un test debe probar una sola cosa**
5. **Los tests deben ser independientes entre sÃ­**

---

## ğŸ”§ BACKEND: TDD con Python + FastAPI + pytest

### 1. Estructura de Archivos (pytest)

**ConvenciÃ³n Oficial de pytest:**

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ auth_service.py          # CÃ³digo de producciÃ³n
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ endpoints/
â”‚           â””â”€â”€ auth.py               # Endpoints
â””â”€â”€ tests/
    â”œâ”€â”€ unit/
    â”‚   â””â”€â”€ services/
    â”‚       â””â”€â”€ test_auth_service.py  # âœ… CORRECTO: test_*.py
    â”‚       â””â”€â”€ auth_service_test.py  # âœ… TAMBIÃ‰N VÃLIDO: *_test.py
    â”‚       â””â”€â”€ auth.service.test.py  # âŒ INCORRECTO: No detectado
    â””â”€â”€ integration/
        â””â”€â”€ test_auth.py              # âœ… CORRECTO
        â””â”€â”€ test_auth_endpoints.py    # âœ… CORRECTO
```

**ConfiguraciÃ³n pytest.ini (Optimizada para LLM):**

```ini
[pytest]
testpaths = tests
python_files = test_*.py *_test.py    # âœ… Convenciones aceptadas
python_classes = Test*
python_functions = test_*
addopts = 
    --cov=app
    --cov-branch                    # âœ… NUEVO: MediciÃ³n de cobertura de ramas
    --cov-report=term-missing
    --cov-report=html
    --cov-fail-under=80             # âœ… AUMENTADO: 70% â†’ 80% (basado en estudios LLM)
    -v
asyncio_mode = auto
markers =
    unit: Unit tests
    integration: Integration tests
    slow: Slow running tests
    critical: Critical business logic tests
```

**âš ï¸ IMPORTANTE:** Los umbrales han sido ajustados basÃ¡ndose en estudios empÃ­ricos de generaciÃ³n de tests con LLMs:
- **Baseline LLM sin guÃ­a:** ~70.2% lÃ­neas, ~52.8% ramas (SchÃ¤fer et al.)
- **Con feedback iterativo:** ~80% mÃ³dulos, ~90% overall (Pizzorno & Berger)
- **Meta industrial:** VerificaciÃ³n de mejora real antes de proponer tests (Alshahwan et al.)

### 2. Nomenclatura de Tests

**PatrÃ³n recomendado:**

```python
# test_auth_service.py

def test_authenticate_user_with_valid_credentials():
    """Should return user when credentials are valid"""
    pass

def test_authenticate_user_with_invalid_password():
    """Should raise AuthenticationError when password is invalid"""
    pass

def test_authenticate_user_with_nonexistent_email():
    """Should raise UserNotFoundError when email doesn't exist"""
    pass
```

**Formato del nombre:**
- `test_<funciÃ³n>_<escenario>_<resultado_esperado>`
- Ejemplo: `test_login_with_invalid_token_returns_401`

### 3. Estructura de Un Test (Arrange-Act-Assert)

```python
# tests/unit/services/test_auth_service.py
import pytest
from app.services.auth_service import AuthService
from app.core.exceptions import AuthenticationError

def test_authenticate_user_with_valid_credentials():
    # ARRANGE: Preparar datos y dependencias
    auth_service = AuthService()
    email = "test@example.com"
    password = "valid_password"
    
    # ACT: Ejecutar la funciÃ³n bajo test
    result = auth_service.authenticate_user(email, password)
    
    # ASSERT: Verificar resultados
    assert result is not None
    assert result.email == email
    assert result.is_authenticated is True

def test_authenticate_user_with_invalid_password_raises_error():
    # ARRANGE
    auth_service = AuthService()
    email = "test@example.com"
    password = "wrong_password"
    
    # ACT & ASSERT: Para excepciones
    with pytest.raises(AuthenticationError) as exc_info:
        auth_service.authenticate_user(email, password)
    
    assert "Invalid credentials" in str(exc_info.value)
```

### 4. Tests de IntegraciÃ³n con FastAPI

```python
# tests/integration/test_auth.py
import pytest
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

def test_login_endpoint_with_valid_credentials():
    # ARRANGE
    payload = {
        "email": "admin@educational.dashboard",
        "password": "admin123"
    }
    
    # ACT
    response = client.post("/api/v1/auth/login", json=payload)
    
    # ASSERT
    assert response.status_code == 200
    data = response.json()
    assert "data" in data
    assert "token" in data["data"]
    assert data["data"]["user"]["email"] == payload["email"]

def test_login_endpoint_with_invalid_credentials_returns_401():
    # ARRANGE
    payload = {
        "email": "admin@educational.dashboard",
        "password": "wrong_password"
    }
    
    # ACT
    response = client.post("/api/v1/auth/login", json=payload)
    
    # ASSERT
    assert response.status_code == 401
    data = response.json()
    assert "error" in data
    assert data["error"]["code"] == "AUTH_INVALID_CREDENTIALS"
```

### 5. Fixtures y Mocks

```python
# tests/conftest.py
import pytest
from app.services.mock_service import MockService

@pytest.fixture
def mock_service():
    """Fixture para proporcionar MockService"""
    service = MockService()
    return service

@pytest.fixture
def test_user():
    """Fixture para proporcionar usuario de prueba"""
    return {
        "id": "test-001",
        "email": "test@example.com",
        "role": "student",
        "name": "Test User"
    }

# Uso en tests
def test_get_user_by_email(mock_service, test_user):
    # ARRANGE
    email = test_user["email"]
    
    # ACT
    result = mock_service.get_user_by_email(email)
    
    # ASSERT
    assert result is not None
    assert result["email"] == email
```

### 6. Tests AsÃ­ncronos

```python
# tests/unit/services/test_google_service.py
import pytest
from app.services.google_service import GoogleService

@pytest.mark.asyncio
async def test_fetch_courses_returns_list():
    # ARRANGE
    google_service = GoogleService()
    
    # ACT
    courses = await google_service.fetch_courses()
    
    # ASSERT
    assert isinstance(courses, list)
    assert len(courses) > 0
    assert "id" in courses[0]
    assert "name" in courses[0]
```

### 7. ParametrizaciÃ³n de Tests

```python
@pytest.mark.parametrize("email,password,expected", [
    ("admin@educational.dashboard", "admin123", True),
    ("teacher@educational.dashboard", "teacher123", True),
    ("invalid@email.com", "wrong", False),
    ("", "", False),
])
def test_authenticate_user_with_various_credentials(email, password, expected):
    # ARRANGE
    auth_service = AuthService()
    
    # ACT
    if expected:
        result = auth_service.authenticate_user(email, password)
        # ASSERT
        assert result is not None
    else:
        # ASSERT
        with pytest.raises(Exception):
            auth_service.authenticate_user(email, password)
```

---

## âš›ï¸ FRONTEND: TDD con React + TypeScript + Vitest

### 1. Estructura de Archivos (Vitest)

**ConvenciÃ³n recomendada:**

```
frontend/src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â”œâ”€â”€ LoginForm.tsx                   # Componente
â”‚   â”‚   â”œâ”€â”€ LoginForm.test.tsx              # âœ… Junto al componente
â”‚   â”‚   â””â”€â”€ __tests__/                      # âœ… O en subdirectorio
â”‚   â”‚       â””â”€â”€ LoginForm.test.tsx
â”‚   â””â”€â”€ dashboards/
â”‚       â”œâ”€â”€ StudentDashboard.tsx
â”‚       â””â”€â”€ StudentDashboard.test.tsx       # âœ… Junto al componente
â”œâ”€â”€ hooks/
â”‚   â”œâ”€â”€ useAuth.ts
â”‚   â””â”€â”€ useAuth.test.ts                     # âœ… Mismo directorio
â””â”€â”€ test/
    â””â”€â”€ setup.ts                             # Setup global
```

**Ambas convenciones son vÃ¡lidas:**
- âœ… `Component.test.tsx` junto al componente
- âœ… `__tests__/Component.test.tsx` en subdirectorio

**ConfiguraciÃ³n vitest.config.ts (Optimizada para LLM):**

```typescript
import { defineConfig } from 'vitest/config'
import react from '@vitejs/plugin-react'
import { resolve } from 'path'

export default defineConfig({
  plugins: [react()],
  test: {
    environment: 'jsdom',
    setupFiles: ['./src/test/setup.ts'],
    globals: true,
    coverage: {
      provider: 'v8',
      reporter: ['text', 'json', 'html'],
      exclude: [
        'node_modules/',
        'src/test/',
      ],
      thresholds: {
        lines: 80,        // âœ… NUEVO: Gate mÃ­nimo para lÃ­neas
        functions: 80,    // âœ… NUEVO: Gate mÃ­nimo para funciones
        statements: 80,   // âœ… NUEVO: Gate mÃ­nimo para statements
        branches: 65      // âœ… NUEVO: Gate mÃ­nimo para ramas (mÃ¡s permisivo)
      }
    },
  },
  resolve: {
    alias: {
      '@': resolve(__dirname, './src'),
    },
  },
})
```

**âš ï¸ IMPORTANTE:** Los thresholds estÃ¡n basados en estudios empÃ­ricos:
- **LÃ­neas/Funciones/Statements:** 80% (basado en mejoras con feedback iterativo)
- **Branches:** 65% (mÃ¡s permisivo, ya que LLMs tienen dificultad con lÃ³gica condicional compleja)

### 2. Setup Global

```typescript
// src/test/setup.ts
import '@testing-library/jest-dom'
import { vi } from 'vitest'

// Mock global de hooks comunes
vi.mock('@/hooks/useTranslation', () => ({
  useTranslation: () => ({
    t: (key: string) => key,
  }),
}))

// Mock de next/navigation si usas Next.js
vi.mock('next/navigation', () => ({
  useRouter: () => ({
    push: vi.fn(),
    replace: vi.fn(),
    back: vi.fn(),
  }),
  usePathname: () => '/',
}))
```

### 3. Testing de Componentes con React Testing Library

**Principios de React Testing Library:**
- **Prueba como el usuario interactÃºa**
- **No pruebes detalles de implementaciÃ³n**
- **Busca elementos por rol, label o texto, no por clase CSS**

```typescript
// StudentDashboard.test.tsx
import { describe, it, expect, vi } from 'vitest'
import { render, screen, waitFor } from '@testing-library/react'
import userEvent from '@testing-library/user-event'
import StudentDashboard from './StudentDashboard'

describe('StudentDashboard Component', () => {
  const mockData = {
    studentId: 'student-001',
    studentName: 'Alice Johnson',
    progress: {
      overall: 0.75,
      coursesCompleted: 3,
      coursesInProgress: 2,
    },
    courses: [
      { id: 'course-001', name: 'Math 101', progress: 0.80, grade: 85 },
      { id: 'course-002', name: 'Science 101', progress: 0.70, grade: 78 },
    ],
  }

  describe('Rendering', () => {
    it('should render dashboard title', () => {
      // ARRANGE & ACT
      render(<StudentDashboard data={mockData} />)
      
      // ASSERT
      expect(screen.getByText(/student dashboard/i)).toBeInTheDocument()
    })

    it('should display student name', () => {
      // ARRANGE & ACT
      render(<StudentDashboard data={mockData} />)
      
      // ASSERT
      expect(screen.getByText(/alice johnson/i)).toBeInTheDocument()
    })

    it('should display progress stats', () => {
      // ARRANGE & ACT
      render(<StudentDashboard data={mockData} />)
      
      // ASSERT
      expect(screen.getByText('Completed')).toBeInTheDocument()
      expect(screen.getByText('3')).toBeInTheDocument()
    })
  })

  describe('User Interactions', () => {
    it('should handle course click', async () => {
      // ARRANGE
      const onCourseClick = vi.fn()
      const user = userEvent.setup()
      
      render(
        <StudentDashboard 
          data={mockData} 
          onCourseClick={onCourseClick} 
        />
      )
      
      // ACT
      const courseButton = screen.getByRole('button', { name: /math 101/i })
      await user.click(courseButton)
      
      // ASSERT
      expect(onCourseClick).toHaveBeenCalledWith('course-001')
    })
  })

  describe('States', () => {
    it('should show loading state', () => {
      // ARRANGE & ACT
      render(<StudentDashboard loading={true} />)
      
      // ASSERT
      expect(screen.getByText(/loading/i)).toBeInTheDocument()
    })

    it('should show error state', () => {
      // ARRANGE & ACT
      render(<StudentDashboard error="Network error" />)
      
      // ASSERT
      expect(screen.getByText(/network error/i)).toBeInTheDocument()
    })
  })
})
```

### 4. Testing de Hooks Personalizados

```typescript
// useAuth.test.ts
import { describe, it, expect, vi, beforeEach } from 'vitest'
import { renderHook, waitFor } from '@testing-library/react'
import { useAuth } from './useAuth'

describe('useAuth Hook', () => {
  beforeEach(() => {
    // Reset mocks antes de cada test
    vi.clearAllMocks()
  })

  it('should return initial state', () => {
    // ARRANGE & ACT
    const { result } = renderHook(() => useAuth())
    
    // ASSERT
    expect(result.current.user).toBeNull()
    expect(result.current.isAuthenticated).toBe(false)
    expect(result.current.isLoading).toBe(true)
  })

  it('should login successfully with valid credentials', async () => {
    // ARRANGE
    const { result } = renderHook(() => useAuth())
    
    // ACT
    await result.current.login('test@example.com', 'password123')
    
    // ASSERT
    await waitFor(() => {
      expect(result.current.isAuthenticated).toBe(true)
      expect(result.current.user).not.toBeNull()
      expect(result.current.user?.email).toBe('test@example.com')
    })
  })

  it('should handle login error', async () => {
    // ARRANGE
    const { result } = renderHook(() => useAuth())
    
    // ACT
    await result.current.login('invalid@example.com', 'wrong')
    
    // ASSERT
    await waitFor(() => {
      expect(result.current.isAuthenticated).toBe(false)
      expect(result.current.error).toBeDefined()
    })
  })
})
```

### 5. Query Priorities (React Testing Library)

**Orden de prioridad para seleccionar elementos:**

1. **`getByRole`** - âœ… MEJOR (accesibilidad)
   ```typescript
   screen.getByRole('button', { name: /submit/i })
   screen.getByRole('textbox', { name: /email/i })
   ```

2. **`getByLabelText`** - âœ… MUY BUENO (forms)
   ```typescript
   screen.getByLabelText(/email address/i)
   ```

3. **`getByPlaceholderText`** - âš ï¸ ACEPTABLE
   ```typescript
   screen.getByPlaceholderText(/enter your email/i)
   ```

4. **`getByText`** - âœ… BUENO (contenido visible)
   ```typescript
   screen.getByText(/welcome back/i)
   ```

5. **`getByTestId`** - âš ï¸ ÃšLTIMO RECURSO
   ```typescript
   screen.getByTestId('custom-element')
   ```

### 6. Queries Variants

```typescript
// getBy* - Lanza error si no encuentra
screen.getByRole('button')  // âŒ Error si no existe

// queryBy* - Retorna null si no encuentra
screen.queryByRole('button')  // âœ… null si no existe

// findBy* - Async, espera hasta encontrar
await screen.findByRole('button')  // âœ… Espera hasta 1000ms

// getAllBy* - Retorna array
screen.getAllByRole('listitem')  // âœ… [item1, item2, ...]
```

### 7. Testing de Async Operations

```typescript
// GoogleConnect.test.tsx
import { describe, it, expect, vi } from 'vitest'
import { render, screen, waitFor } from '@testing-library/react'
import userEvent from '@testing-library/user-event'
import GoogleConnect from './GoogleConnect'

describe('GoogleConnect Component', () => {
  it('should fetch and display courses on connect', async () => {
    // ARRANGE
    const user = userEvent.setup()
    render(<GoogleConnect />)
    
    // ACT
    const connectButton = screen.getByRole('button', { name: /connect/i })
    await user.click(connectButton)
    
    // ASSERT
    // Esperar a que aparezca el loading
    expect(screen.getByText(/loading/i)).toBeInTheDocument()
    
    // Esperar a que aparezcan los cursos
    await waitFor(() => {
      expect(screen.getByText(/math 101/i)).toBeInTheDocument()
    }, { timeout: 3000 })
  })
})
```

---

## ğŸ¯ Mejores PrÃ¡cticas Generales

### 1. Nombres Descriptivos

**âŒ MAL:**
```typescript
test('test1', () => { ... })
test('should work', () => { ... })
```

**âœ… BIEN:**
```typescript
test('should authenticate user with valid credentials', () => { ... })
test('should return 401 when token is expired', () => { ... })
```

### 2. Un Test, Un Concepto

**âŒ MAL:**
```typescript
test('login functionality', () => {
  // Prueba login
  // Prueba logout
  // Prueba refresh token
  // Demasiadas cosas
})
```

**âœ… BIEN:**
```typescript
test('should login user with valid credentials', () => { ... })
test('should logout user and clear session', () => { ... })
test('should refresh token when expired', () => { ... })
```

### 3. Tests Independientes

**âŒ MAL:**
```typescript
let sharedData;

test('test1', () => {
  sharedData = createData()  // âŒ Estado compartido
})

test('test2', () => {
  expect(sharedData).toBeDefined()  // âŒ Depende de test1
})
```

**âœ… BIEN:**
```typescript
test('test1', () => {
  const data = createData()  // âœ… Estado local
  expect(data).toBeDefined()
})

test('test2', () => {
  const data = createData()  // âœ… Independiente
  expect(data).toBeDefined()
})
```

### 4. Tests RÃ¡pidos

- **Unit tests:** < 50ms cada uno
- **Integration tests:** < 500ms cada uno
- **E2E tests:** Pueden ser mÃ¡s lentos

```python
# Marcar tests lentos
@pytest.mark.slow
def test_full_sync_operation():
    pass
```

### 5. Cobertura de Tests (Optimizada para LLM)

**Objetivos basados en estudios empÃ­ricos:**

| Tipo | MÃ­nimo | Recomendado | CrÃ­ticos |
|------|--------|-------------|----------|
| **LÃ­neas** | 80% | 85% | 90% |
| **Funciones** | 80% | 85% | 90% |
| **Branches** | 65% | 75% | 80% |
| **Statements** | 80% | 85% | 90% |

```bash
# Backend (con branch coverage)
pytest --cov=app --cov-branch --cov-report=html

# Frontend (con thresholds)
pnpm test -- --coverage
```

**âš ï¸ IMPORTANTE - Evidencia EmpÃ­rica:**
- **Baseline LLM sin guÃ­a:** ~70.2% lÃ­neas, ~52.8% ramas (SchÃ¤fer et al.)
- **Con feedback iterativo:** ~80% mÃ³dulos, ~90% overall (Pizzorno & Berger)
- **Meta industrial:** VerificaciÃ³n de mejora real antes de proponer tests (Alshahwan et al.)

**Priorizar cobertura en:**
- âœ… LÃ³gica de negocio crÃ­tica (90% lÃ­neas, 80% ramas)
- âœ… Manejo de errores (90% lÃ­neas, 80% ramas)
- âœ… Casos edge (85% lÃ­neas, 75% ramas)
- âš ï¸ No obsesionarse con 100% (ley de rendimientos decrecientes)

### 6. OrganizaciÃ³n de Tests

```
tests/
â”œâ”€â”€ unit/                    # Tests unitarios aislados
â”‚   â”œâ”€â”€ services/
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ integration/             # Tests de integraciÃ³n
â”‚   â”œâ”€â”€ api/
â”‚   â””â”€â”€ database/
â”œâ”€â”€ e2e/                     # Tests end-to-end
â”‚   â””â”€â”€ user_flows/
â””â”€â”€ fixtures/                # Datos de prueba compartidos
    â””â”€â”€ test_data.json
```

---

## ğŸ“‹ Checklist de TDD

### Antes de Empezar
- [ ] Entiendo el requisito que voy a implementar
- [ ] SÃ© quÃ© comportamiento espero
- [ ] Tengo claro quÃ© casos edge considerar

### Durante el Desarrollo
- [ ] âœï¸ EscribÃ­ el test primero
- [ ] ğŸ”´ VerifiquÃ© que el test falla (RED)
- [ ] ğŸ’» EscribÃ­ el cÃ³digo mÃ­nimo necesario
- [ ] ğŸŸ¢ El test ahora pasa (GREEN)
- [ ] ğŸ”§ RefactoricÃ© manteniendo tests verdes (REFACTOR)
- [ ] ğŸ“ El nombre del test es descriptivo
- [ ] ğŸ¯ El test prueba una sola cosa
- [ ] âš¡ El test es rÃ¡pido (< 50ms unit, < 500ms integration)

### DespuÃ©s de Implementar
- [ ] âœ… Todos los tests pasan
- [ ] ğŸ“Š La cobertura cumple el mÃ­nimo (â‰¥80% lÃ­neas, â‰¥65% ramas)
- [ ] ğŸ¯ MÃ³dulos crÃ­ticos alcanzan â‰¥90% lÃ­neas, â‰¥80% ramas
- [ ] ğŸ” Los tests son legibles y mantenibles
- [ ] ğŸ“š DocumentÃ© comportamientos complejos
- [ ] ğŸ—‘ï¸ EliminÃ© tests duplicados o innecesarios
- [ ] ğŸ”„ Verifico mejora real de cobertura (no solo nÃºmeros)

---

## ğŸš€ Comandos Ãštiles

### Backend (pytest)
```bash
# Ejecutar todos los tests
pytest

# Tests con cobertura
pytest --cov=app --cov-report=html

# Tests especÃ­ficos
pytest tests/unit/services/test_auth_service.py

# Tests con marca especÃ­fica
pytest -m unit
pytest -m integration

# Tests en modo watch (con pytest-watch)
ptw

# Tests verbose
pytest -v

# Tests con output completo
pytest -vv
```

### Frontend (Vitest)
```bash
# Ejecutar todos los tests
pnpm test

# Tests en modo watch
pnpm test --watch

# Tests con cobertura
pnpm test --coverage

# Tests especÃ­ficos
pnpm test StudentDashboard

# Tests en modo UI
pnpm test --ui

# Tests verbose
pnpm test --reporter=verbose
```

---

## ğŸ“š Referencias Oficiales

### DocumentaciÃ³n TÃ©cnica
1. **pytest Documentation:** https://docs.pytest.org/
2. **Vitest Documentation:** https://vitest.dev/
3. **React Testing Library:** https://testing-library.com/react
4. **FastAPI Testing:** https://fastapi.tiangolo.com/tutorial/testing/
5. **MDN Testing Guide:** https://developer.mozilla.org/en-US/docs/Learn/Tools_and_testing
6. **Kent Beck - TDD by Example:** Libro fundamental sobre TDD

### Estudios EmpÃ­ricos LLM + Testing
7. **SchÃ¤fer et al.** - [An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation](https://arxiv.org/abs/2302.06527) - Baseline: ~70.2% lÃ­neas, ~52.8% ramas
8. **Pizzorno & Berger** - [CoverUp: Coverage-Guided LLM-Based Test Generation](https://arxiv.org/abs/2403.16218) - Feedback iterativo: ~80% mÃ³dulos, ~90% overall
9. **Ryan et al.** - [SymPrompt: Code-Aware Prompting, Coverage-Guided Test Generation](https://dl.acm.org/doi/10.1145/3643769) - Prompting code-aware
10. **Alshahwan et al.** - [Automated Unit Test Improvement using LLMs at Meta](https://arxiv.org/abs/2402.09171) - Despliegue industrial
11. **Alshahwan et al.** - [Observation-based unit test generation at Meta](https://arxiv.org/abs/2402.06111) - 518 tests, 9.6M ejecuciones CI

### GuÃ­as de Cobertura
12. **Google Testing Blog** - [Code Coverage Best Practices](https://testing.googleblog.com/2020/08/code-coverage-best-practices.html) - 60% aceptable, 75% commendable, 90% exemplary
13. **Google Testing Blog** - [Code coverage goal: 80% and no less!](https://testing.googleblog.com/2010/07/code-coverage-goal-80-and-no-less.html) - Regla simple

---

## ğŸ“ ConclusiÃ³n

TDD es una **disciplina** que requiere prÃ¡ctica y compromiso, pero los beneficios son significativos:

- âœ… **Mejor diseÃ±o de cÃ³digo** (cÃ³digo mÃ¡s modular y testeable)
- âœ… **Menos bugs en producciÃ³n** (detecciÃ³n temprana)
- âœ… **Refactoring seguro** (confianza para cambiar cÃ³digo)
- âœ… **DocumentaciÃ³n viva** (los tests documentan comportamiento)
- âœ… **Desarrollo mÃ¡s rÃ¡pido** (menos debugging, mÃ¡s confianza)

### ğŸ¤– TDD Optimizado para LLM

Con la evidencia empÃ­rica disponible, hemos ajustado los umbrales de cobertura para aprovechar las capacidades superiores de los LLMs:

- **80% lÃ­neas/funciones** (vs 70% tradicional) - Basado en estudios de feedback iterativo
- **65% ramas** (mÃ¡s permisivo) - Reconociendo limitaciones en lÃ³gica condicional compleja
- **90% crÃ­ticos** - Para mÃ³dulos de negocio crÃ­ticos
- **VerificaciÃ³n de mejora real** - No solo nÃºmeros, sino calidad de tests

**Recuerda:** Los tests no son el objetivo, son una herramienta para escribir mejor software. Con LLMs, podemos aspirar a estÃ¡ndares mÃ¡s altos de manera eficiente.

---

**Ãšltima actualizaciÃ³n:** 2025-10-02  
**Proyecto:** Dashboard Educativo  
**Mantenedor:** Leopoldo Brines

